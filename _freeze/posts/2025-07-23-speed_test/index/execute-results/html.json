{
  "hash": "12f9220df959dabe5233c65921c3a660",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Speed Testing: Three Levels\"\nauthor: \"Kelly Bodwin\"\ndate: \"2025-07-23\"\ndraft: false\ncategories: [programming, tutorial]\nimage: \"\"\nknitr:\n  opts_chunk: \n    collapse: true\n    comment: \"#>\" \nexecute:\n  error: true\n  message: false\n---\n\n\n\nWhile it's fresh in my mind (mostly thanks to [Tyson Barrett's awesome material from our USCOTS workshop](https://atheobold.github.io/uscots-intermediate-r/materials/08-developer.html)), I want to jot down the different ways to speed test your R Code.\n\nFirst, let's load up the packages I'll use:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#pak::pak(c(\"nycflights13\", \"microbenchmark\", \"profvis\", \"bench\", \"tictoc\", \"atime\", \"dtplyr\"))\nlibrary(tidyverse)\nlibrary(nycflights13)\nlibrary(microbenchmark)\nlibrary(bench)\nlibrary(tictoc)\nlibrary(atime)\nlibrary(profvis)\n```\n:::\n\n\n\nNow let's make a little pipeline with nontrivial compute time (on my laptop, at least) that we can use to test things.  I'm totally cheating here by just duplicating the dataset 10 times to make it bigger.  And also ChatGPT wrote my pipeline.  Anyways...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_big <- bind_rows(replicate(10, flights, simplify = FALSE))\n\n\nflights_big |>\n  filter(!is.na(air_time), !is.na(tailnum), !is.na(dep_delay)) |>\n  group_by(tailnum) |>\n  summarise(\n    mean_air_time = mean(air_time),\n    sd_air_time = sd(air_time),\n    n = n(),\n    delay_score = sum((dep_delay)^2) / n()\n  ) |>\n  left_join(planes, by = \"tailnum\") |>\n  mutate(\n    model_length = str_length(model),\n    manufacturer_upper = str_to_upper(manufacturer)\n  ) |>\n  filter(!is.na(model_length), n > 50) |>\n  arrange(desc(delay_score))\n#> # A tibble: 2,906 × 15\n#>    tailnum mean_air_time sd_air_time     n delay_score  year type   manufacturer\n#>    <chr>           <dbl>       <dbl> <int>       <dbl> <int> <chr>  <chr>       \n#>  1 N384HA          626.        24.8    330      51368.  2011 Fixed… AIRBUS      \n#>  2 N276AT          114.         8.41    60      37738.  2005 Fixed… BOEING      \n#>  3 N6716C          202.        86.4    250      32628.  2001 Fixed… BOEING      \n#>  4 N550NW          108.         3.56    70      24047.  2001 Fixed… BOEING      \n#>  5 N203FR          233.        16.9    410      21445.  2002 Fixed… AIRBUS INDU…\n#>  6 N184DN          239.       107.     160      18789.  1993 Fixed… BOEING      \n#>  7 N521VA          334.        15.4    270      18686.  2006 Fixed… AIRBUS      \n#>  8 N927DA          137.        21.3    820      17802.  1988 Fixed… MCDONNELL D…\n#>  9 N635AA          185.        58.1    290      15948.  1990 Fixed… BOEING      \n#> 10 N923FJ           90.2        7.47   120      15756.  2004 Fixed… BOMBARDIER …\n#> # ℹ 2,896 more rows\n#> # ℹ 7 more variables: model <chr>, engines <int>, seats <int>, speed <int>,\n#> #   engine <chr>, model_length <int>, manufacturer_upper <chr>\n```\n:::\n\n\n\nSo that I don't have to copy-paste that long pipeline several times, I'm going to wrap it in a quick silly function.  You don't need to do this in your workflow, it's just saving blog post space.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndo_the_thing <- function(dat) {\n  \n  temp <-  flights_big |>\n  filter(!is.na(air_time), !is.na(tailnum), !is.na(dep_delay)) |>\n  group_by(tailnum) |>\n  summarise(\n    mean_air_time = mean(air_time),\n    sd_air_time = sd(air_time),\n    n = n(),\n    delay_score = sum((dep_delay)^2) / n()\n  ) |>\n  left_join(planes, by = \"tailnum\") |>\n  mutate(\n    model_length = str_length(model),\n    manufacturer_upper = str_to_upper(manufacturer)\n  ) |>\n  filter(!is.na(model_length), n > 50) |>\n  arrange(desc(delay_score))\n  \n   return(\"done\")\n}\n```\n:::\n\n\n\n\n## Level 1: Quick time checks\n\nMost often, I just need a quick-and-dirty way to see approximately how long my code snippet is taking.  Usually this is so I can estimate how long it will take to repeat many times; e.g. if I'm running some simulations in an experiment.\n\ntl;dr - Use `proc.time()` or the `tictoc` package.\n\n### Maybe don't use this: `Sys.time()`\n\nA function that newer R users tend to know or find is `Sys.time()` to record the current time. So to speed test code, they will (reasonably) just check the time then manually calculate how much has elapsed:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\n\ndo_the_thing(flights_big)\n#> [1] \"done\"\n\nnow <- Sys.time() - start_time\n\nprint(now)\n#> Time difference of 0.2220261 secs\n```\n:::\n\n\n\n\nOne critique of this method is that it's just measuring how much time elapsed in real life, not necessarily how much was spent on the code I'm testing.  That is, if you have some other giant computation running on your computer at the same time, this might appear slower.  More on that in a sec. For many users, wanting more of a quick look at a slowdown than a precise compute time, that's not a big deal.\n\nThe real main drawback of this approach, aside from stylistic preference, is that the object you get from subtracting times is a `difftime`. I don't like these, because they essentially return a number, with an *attribute* tacked on letting you know if it's seconds or minutes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(now)\n#> [1] \"difftime\"\n\nstr(now)\n#>  'difftime' num 0.222026109695435\n#>  - attr(*, \"units\")= chr \"secs\"\n```\n:::\n\n\nHere's why that is bad.  Suppose I have one task that takes a fraction of a second, and one task that takes a few minutes.\n\nI time these out and I convert them to *doubles* so I can do math on them without the pesky `difftime` tagalong info.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\n\nfor (i in 1:300) {\n  do_the_thing(flights_big)\n}\n\nnow_2 <- Sys.time() - start_time\n\nnow_2\n#> Time difference of 1.093376 mins\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nas.double(now)\n#> [1] 0.2220261\nas.double(now_2)\n#> [1] 1.093376\n```\n:::\n\n\n\nHmmm.... doing the task 300 times only took a little longer than doing it once?  Very suspicious...\n\nOf course, this problem is easy to avoid - and realistically, you'd more likely be just printing your times out than saving them somewhere - but it's also a fairly easy pit to fall into while making reasonable choices.\n\n### Base R has your back: `proc.time()` and `system.time()`\n\nYou can get around both criticisms of `Sys.time()` simply by using `proc.time()` instead:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- proc.time()\n\ndo_the_thing(flights_big)\n#> [1] \"done\"\n\n\nnow <- proc.time() - start_time\n\nprint(now)\n#>    user  system elapsed \n#>   0.171   0.048   0.219\n```\n:::\n\n\n\nThe `now` object is technically a `proc_time` object, but really it's essentially just a named vector.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(now)\n#> [1] \"proc_time\"\nstr(now)\n#>  'proc_time' Named num [1:5] 0.171 0.048 0.219 0 0\n#>  - attr(*, \"names\")= chr [1:5] \"user.self\" \"sys.self\" \"elapsed\" \"user.child\" ...\n```\n:::\n\n\n\n\n\nThe interesting bit here for now is the `elapsed` part - the distinction between `user` computations and `system` computations is subtle, and if it matters to your development, you're probably better off using a helper package like those as the end of this post.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnow[3]\n#> elapsed \n#>   0.219\n```\n:::\n\n\n\nSince this is just a vector of doubles, and it's consistently returned in seconds, there's no danger of mixing and matching different units in weird ways.\n\nFor an alternate syntax, instead of calling `proc.time()` twice, you can call your code inside of `system.time()`, which is nice is your snippet is short:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({\n  do_the_thing(flights_big)\n})\n#>    user  system elapsed \n#>   0.159   0.037   0.198\n```\n:::\n\n\n\n\n\n### But wrappers are convenient: `tictoc()`\n\nMy favorite timing package is `tictoc()`, which is basically just a cute wrapper doing the same thing as `proc.time()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\n\ndo_the_thing(flights_big)\n#> [1] \"done\"\n\ntoc()\n#> 0.216 sec elapsed\n```\n:::\n\n\n\n\nLike the `Sys.time()` approach, this one is really meant for quick timing printouts, not for saving results of many experiments.  If you do want to save the result, you'll find a *list* rather than a `difftime` or `proc_time`, even though the text printout looks the same as the difftimes did:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\n\ndo_the_thing(flights_big)\n#> [1] \"done\"\n\nnow <- toc()\n#> 0.224 sec elapsed\n\nclass(now)\n#> [1] \"list\"\nstr(now)\n#> List of 4\n#>  $ tic         : Named num 3.18\n#>   ..- attr(*, \"names\")= chr \"elapsed\"\n#>  $ toc         : Named num 3.4\n#>   ..- attr(*, \"names\")= chr \"elapsed\"\n#>  $ msg         : logi(0) \n#>  $ callback_msg: chr \"0.224 sec elapsed\"\n```\n:::\n\n\n\nWhen you access the actual time measurement (`$toc`), it consistently returns a your time as a double in milliseconds.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnow$toc\n#> elapsed \n#>   3.405\n\nstr(now$toc)\n#>  Named num 3.4\n#>  - attr(*, \"names\")= chr \"elapsed\"\n```\n:::\n\n\n\nAnother feature of `tictoc()` - although not one I see used often - is the ability to automatically keep a log of several `tic()` and `toc()` results.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic.clearlog()\n\nfor (x in 1:10) {\n   tic(x)\n   do_the_thing(flights_big)\n   toc(log = TRUE, quiet = TRUE)\n}\n\nresults <- tic.log()\nresults_raw <- tic.log(format = FALSE)\ntic.clearlog()\n\n```\n:::\n\n\n\nBy default, the log gives a list of the messages in text form:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults[1:2]\n#> [[1]]\n#> [1] \"1: 0.221 sec elapsed\"\n#> \n#> [[2]]\n#> [1] \"2: 0.208 sec elapsed\"\n```\n:::\n\n\n\nHowever, you can also get the raw `toc()` object results:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_raw[1:2]\n#> [[1]]\n#> [[1]]$tic\n#> elapsed \n#>   3.414 \n#> \n#> [[1]]$toc\n#> elapsed \n#>   3.635 \n#> \n#> [[1]]$msg\n#> [1] 1\n#> \n#> [[1]]$callback_msg\n#> [1] \"1: 0.221 sec elapsed\"\n#> \n#> \n#> [[2]]\n#> [[2]]$tic\n#> elapsed \n#>   3.635 \n#> \n#> [[2]]$toc\n#> elapsed \n#>   3.843 \n#> \n#> [[2]]$msg\n#> [1] 2\n#> \n#> [[2]]$callback_msg\n#> [1] \"2: 0.208 sec elapsed\"\n```\n:::\n\n\n\nIt's messy to look at, but it plays nice with some `tidyverse` functions to yank out a vector of results in numeric form:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_raw |>\n  map_dbl(~pluck(.x, \"toc\"))\n#>  [1] 3.635 3.843 4.060 4.310 4.766 5.135 5.404 5.671 5.928 6.205\n```\n:::\n\n\n\n## Level 2: Benchmarking\n\nNow, if you are finding slowdowns in your code, you are probably also trying solutions to speed them up - whether this is different rearrangements of your pipeline, or calling in help from other packages.  You'll want to see which approach sped your code up best, and by how much.  This is called **Benchmarking**.\n\nFor example, let's consider running the gnarly pipeline with the `data.table` package instead.  Since I don't feel like translating the whole pipeline to the `data.table` syntax, instead I'll just lean on the [`dtplyr` package](https://dtplyr.tidyverse.org/) to do it for me.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dtplyr)\n\ndo_the_thing_dt <- function(dat) {\n  \n temp <- dat |>\n  lazy_dt() |>\n  filter(!is.na(air_time), !is.na(tailnum), !is.na(dep_delay)) |>\n  group_by(tailnum) |>\n  summarise(\n    mean_air_time = mean(air_time),\n    sd_air_time = sd(air_time),\n    n = n(),\n    delay_score = sum((dep_delay)^2) / n()\n  ) |>\n  left_join(planes, by = \"tailnum\") |>\n  mutate(\n    model_length = str_length(model),\n    manufacturer_upper = str_to_upper(manufacturer)\n  ) |>\n  filter(!is.na(model_length), n > 50) |>\n  arrange(desc(delay_score))\n \n return(\"done\")\n  \n}\n```\n:::\n\n\n\nA quick timing shows that we sped our code up by almost 5 times!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\ndo_the_thing(flights_big)\n#> [1] \"done\"\ntoc()\n#> 0.217 sec elapsed\n\ntic()\ndo_the_thing_dt(flights_big)\n#> [1] \"done\"\ntoc()\n#> 0.067 sec elapsed\n```\n:::\n\n\n\n### Repeated tests with `microbenchmark()`\n\nAs you may have noticed throughout this post, running the exact same code twice doesn't always take the exact same amount of time.\n\nThe `microbenchmark` package is helpful if you want to do a true experiment, and run the different approaches each many times before making a comparison.  By default, it will run your code 100 times - be aware of how long this will take total before you start running code!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicrobenchmark(\n  dplyr_version = do_the_thing(flights_big),\n  dt_version = do_the_thing_dt(flights_big)\n)\n#> Warning in microbenchmark(dplyr_version = do_the_thing(flights_big), dt_version\n#> = do_the_thing_dt(flights_big)): less accurate nanosecond times to avoid\n#> potential integer overflows\n#> Unit: milliseconds\n#>           expr       min        lq      mean    median        uq      max neval\n#>  dplyr_version 210.06674 250.41693 257.65915 257.91749 268.71517 394.9760   100\n#>     dt_version  29.93234  40.30591  60.23163  53.06985  79.15314 124.5242   100\n```\n:::\n\n\n\n### Size experiments with `bench`\n\nWe saw that using `data.table` bought us quite a bit of time in this case.  But would it be worth it if we hadn't made the giant 10x version of the dataset?\n\nThe `bench` package has essentially the same syntax as `microbenchmark`, except that:\n\n* It only runs each code snippet once\n\n* It (very annoyingly) requires the output to be identical for the two snippets.  I got around this by just returning \"done\" in each function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbench::mark(\n  dplyr_version = do_the_thing(flights_big),\n  dt_version = do_the_thing_dt(flights_big)\n)\n#> Warning: Some expressions had a GC in every iteration; so filtering is\n#> disabled.\n#> # A tibble: 2 × 6\n#>   expression         min   median `itr/sec` mem_alloc `gc/sec`\n#>   <bch:expr>    <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n#> 1 dplyr_version  232.1ms    257ms      3.91     634MB     9.11\n#> 2 dt_version      61.2ms    105ms     10.6      386MB    10.6\n```\n:::\n\n\n\nSo why would we use it?  First, because you also get **memory** results, which I've kind of swept under the rug in this post.  Usually, memory and speed results agree with each other, and we're more interested in speed.  But if you are benchmarking because you are worried about maxing out your memory, this is nice to have.\n\nIn this case, the code took about 600 MB and 400 MB of memory... my current laptop has 16,000 MB available, and R on Mac can typically access all of that, so no worries there!  But perhaps if I wanted to run this code thousands of times, I might need to be careful with how much I store and how much I run in parallel.\n\nAnyways.  Without digressing too far into memory stuff - the reason to use `bench` over `microbenchmark` is to see how your speed improvements scale with size.  We'll use `bench::press()` to establish a set of values, then we'll make a version of our `flights_big` dataset for each value, then we'll benchmark our two versions of the code on those datasets.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- bench::press(\n  duplications = c(2, 10, 20),\n  {\n    flights_big <- bind_rows(replicate(duplications, flights, simplify = FALSE))\n    bench::mark(\n        dplyr_version = do_the_thing(flights_big),\n        dt_version = do_the_thing_dt(flights_big)\n    )\n  }\n)\n#> Warning: Some expressions had a GC in every iteration; so filtering is\n#> disabled.\n#> Warning: Some expressions had a GC in every iteration; so filtering is\n#> disabled.\n#> Warning: Some expressions had a GC in every iteration; so filtering is\n#> disabled.\n\nresults\n#> # A tibble: 6 × 7\n#>   expression    duplications      min   median `itr/sec` mem_alloc `gc/sec`\n#>   <bch:expr>           <dbl> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n#> 1 dplyr_version            2 244.33ms  275.5ms      3.63   634.3MB     9.08\n#> 2 dt_version               2   8.02ms     10ms     62.9     77.4MB     9.82\n#> 3 dplyr_version           10 209.62ms  271.1ms      3.69   634.3MB     7.38\n#> 4 dt_version              10  34.36ms   64.5ms     13.2    385.7MB    11.3 \n#> 5 dplyr_version           20 351.19ms  359.6ms      2.78   634.3MB     9.73\n#> 6 dt_version              20 101.77ms  119.1ms      6.93   771.1MB     5.20\n```\n:::\n\n\n\nSo, does the advantage of `data.table` scale linearly as the data gets bigger?  Not really - both methods only get slightly slower as the data gets bigger, so dt goes from being something like 25 times faster on the small dataset to only 3 times faster on the large one.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nresults |>\n  mutate(\n    version = rep(c(\"dplyr\", \"data.table\"), 3),\n    median_time = as.double(median)\n  ) |>\n  ggplot() +\n  aes(x = duplications, y = median_time, color = version) +\n  geom_point() +\n  geom_line() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\n:::{.callout-note}\n\nI'm being a little unfair to `data.table` here.  The vast, vast majority of the time spent in the `do_the_thing_dt()` function is in converting the data frame to a `data.table` object with `lazy_dt()`.\n\nSo basically, if you're going to convert your data to a `data.table` once and then run a ton of pipelines/repetitions, then `data.table` is super helpful in larger data.  But if it's a one-off process, the cost of creating the `data.table` object is more than the speed-up of the code.\n\nHow do I know the time breakdown of the `do_the_thing_dt()` function?  Read on...\n\n:::\n\n## Level 3: Profiling\n\nThe next notch up is to figure out where exactly, in our long pipeline, the slowdown is happening. This is called *Profiling*. \n\n### Quick look with `profviz`\n\n`profviz` is a tool that makes interactive plots to explore the computation time of each routine and subroutine in your code. This time I'm copying the whole pipeline, so that `profviz` will measure the different steps instead of just the wrapper function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprofvis({\n  flights_big |>\n  filter(!is.na(air_time), !is.na(tailnum), !is.na(dep_delay)) |>\n  group_by(tailnum) |>\n  summarise(\n    mean_air_time = mean(air_time),\n    sd_air_time = sd(air_time),\n    n = n(),\n    delay_score = sum((dep_delay)^2) / n()\n  ) |>\n  left_join(planes, by = \"tailnum\") |>\n  mutate(\n    model_length = str_length(model),\n    manufacturer_upper = str_to_upper(manufacturer)\n  ) |>\n  filter(!is.na(model_length), n > 50) |>\n  arrange(desc(delay_score))\n})\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"profvis html-widget html-fill-item\" id=\"htmlwidget-550f3026659f3c4a840b\" style=\"width:100%;height:600px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-550f3026659f3c4a840b\">{\"x\":{\"message\":{\"prof\":{\"time\":[1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,14,14,15,15,16,16,17,17,17,18,18,18,19,19,19,20,20,20,21,21,21,22,22,23,23,24,24,25,25,26,26,27,27,28,28,29,29,30,30,31,31,32,32,33,33,34,34,35,35,36,36,37,37,38,38,39,39,40,40,41,41,42,42,43,43,44,44,45,45,46,46,47,47,48,48,49,49,50,50,51,51,52,52,53,53,54,54,55,55,56,56,57,57,58,58,59,59,60,60,61,61,62,62,62,63,63,63,64,64,64,65,65,65,66,66,66,67,67,67,68,68,69,69,70,70,71,71,72,72,73,73,74,74,75,75,76,76,77,77,78,78,79,79,80,80,81,81,82,82,83,83,84,84,85,85,86,86,87,87,88,88,89,89,90,90,91,91,92,92,93,93,94,94,95,95,96,96,97,97,98,98,99,99,99,100,100,100,101,101,101,101,102,102,102,103,103,103,104,104,104,105,105,105,105,106,106,106,106,107,107,107,107,108,108,108,108,109,109,109,109,110,110,110,110,111,111,111,111,112,112,112,113,113,113,114,115,115,115,115,115,116,116,117,117,118,118,119,119,120,120,121,121,121,122,122,122,122,122],\"depth\":[2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,3,2,1,3,2,1,3,2,1,3,2,1,3,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,3,2,1,3,2,1,3,2,1,3,2,1,3,2,1,3,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,3,2,1,3,2,1,4,3,2,1,3,2,1,3,2,1,3,2,1,4,3,2,1,4,3,2,1,4,3,2,1,4,3,2,1,4,3,2,1,4,3,2,1,4,3,2,1,3,2,1,3,2,1,1,5,4,3,2,1,2,1,2,1,2,1,2,1,2,1,3,2,1,5,4,3,2,1],\"label\":[\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"<GC>\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"lazyLoadDBfetch\",\".main\",\"is.na\",\".main\",\".Call\",\".main\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"<GC>\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\"vec_slice\",\"dplyr_row_slice.data.frame\",\"filter.data.frame\",\".main\",\"vec_locate_sorted_groups\",\"dplyr_locate_sorted_groups\",\"compute_groups\",\"grouped_df\",\"group_by.data.frame\",\"<Anonymous>\",\".main\",\"mean\",\".main\",\"sd\",\".main\",\".Call\",\".main\",\"<Anonymous>\",\".main\",\"<Anonymous>\",\"n\",\".main\",\"%||%\",\"context_peek\",\"peek_mask\",\"n\",\".main\"],\"filenum\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"linenum\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"memalloc\":[142.1263046264648,142.1263046264648,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3420257568359,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3225631713867,572.3224411010742,572.3224411010742,572.3224411010742,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1002.538154602051,1028.233245849609,1028.233245849609,1053.927215576172,1053.927215576172,1066.774200439453,1066.774200439453,1092.468170166016,1092.468170166016,1105.315155029297,1105.315155029297,1118.162139892578,1118.162139892578,1143.856109619141,1143.856109619141,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1169.550079345703,1182.397064208984,1182.397064208984,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,1208.091033935547,777.8753128051758,777.8753128051758,777.8753128051758,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,739.7323379516602,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,765.4263076782227,791.1202774047852,791.1202774047852,816.8142471313477,816.8142471313477,816.8142471313477,816.8142471313477,842.5082168579102,842.5082168579102,868.2021865844727,868.2021865844727,893.8961563110352,893.8961563110352,893.8961563110352,893.8961563110352,958.1410598754883,958.1410598754883,1009.52904510498,1009.52904510498,1071.968605041504,1071.968605041504,1071.968605041504,1159.379600524902,1159.379600524902,1159.379600524902,1196.841438293457,1196.841438293457,1196.841438293457,1196.841438293457,1131.874473571777,1131.874473571777,1131.874473571777,1156.849021911621,1156.849021911621,1156.849021911621,1181.823570251465,1181.823570251465,1181.823570251465,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,1206.798149108887,801.5551300048828,801.5551300048828,801.5551300048828,876.4787902832031,876.4787902832031,876.4787902832031,917.6076278686523,928.6079940795898,928.6079940795898,928.6079940795898,928.6079940795898,928.6079940795898,947.5077133178711,947.5077133178711,956.0597076416016,956.0597076416016,957.3503952026367,957.3503952026367,958.616584777832,958.616584777832,959.5913009643555,959.5913009643555,985.1990509033203,985.1990509033203,985.1990509033203,953.9970397949219,953.9970397949219,953.9970397949219,953.9970397949219,953.9970397949219],\"meminc\":[0,0,430.2157211303711,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.01946258544921875,0,0,0,0,0,0,0,0,0,0,0,-0.0001220703125,0,0,430.2157135009766,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25.69509124755859,0,25.6939697265625,0,12.84698486328125,0,25.6939697265625,0,12.84698486328125,0,12.84698486328125,0,25.6939697265625,0,25.6939697265625,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12.84698486328125,0,25.6939697265625,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-430.2157211303711,0,0,-38.14297485351562,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25.6939697265625,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25.6939697265625,0,25.6939697265625,0,0,0,25.6939697265625,0,25.6939697265625,0,25.6939697265625,0,0,0,64.24490356445312,0,51.38798522949219,0,62.43955993652344,0,0,87.41099548339844,0,0,37.46183776855469,0,0,0,-64.96696472167969,0,0,24.97454833984375,0,0,24.97454833984375,0,0,24.97457885742188,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-405.2430191040039,0,0,74.92366027832031,0,0,41.12883758544922,11.0003662109375,0,0,0,0,18.89971923828125,0,8.551994323730469,0,1.290687561035156,0,1.266189575195312,0,0.9747161865234375,0,25.60774993896484,0,0,-31.20201110839844,0,0,0,0],\"filename\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]},\"interval\":10,\"files\":[],\"prof_output\":\"/var/folders/st/pw77hjgj43v89ypp8n67vdb00000gn/T//RtmpDCxQ6D/file23c423928ffa.prof\",\"highlight\":{\"output\":[\"^output\\\\$\"],\"gc\":[\"^<GC>$\"],\"stacktrace\":[\"^\\\\.\\\\.stacktraceo(n|ff)\\\\.\\\\.$\"]},\"split\":\"h\"}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n<br>\n<br>\n\nWhat is this telling us?  We can see from the bottom \"stack\" of the plot that `filter` is by far the slowest step in our pipeline.\n\n\n### Detail (too much?) with `Rprof`\n\nThe Base R way to profile requires little fiddling.\n\nFirst, we profile the code and save it to a `.out` file:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRprof(\"results.out\")\ndo_the_thing(flights_big)\n#> [1] \"done\"\nRprof(NULL)\n```\n:::\n\n\n\nThen, if we want to see the results, we have to read the `results.out` file using helper functions like:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummaryRprof(\"results.out\")$by.self\n#>                            self.time self.pct total.time total.pct\n#> \"vec_slice\"                     0.16    61.54       0.16     61.54\n#> \"^\"                             0.02     7.69       0.02      7.69\n#> \"<Anonymous>\"                   0.02     7.69       0.02      7.69\n#> \"mean\"                          0.02     7.69       0.02      7.69\n#> \"stopifnot\"                     0.02     7.69       0.02      7.69\n#> \"vec_locate_sorted_groups\"      0.02     7.69       0.02      7.69\n```\n:::\n\n\nThis is telling us that the slowest procedure was `vec_slice`; which we could track down and find is part of the `filter` step.\n\nThere are a number of helper packages and functions for visualizing or understanding the full profiling output (e.g. `profr`, `proftools`)\n\n\n\n## Addendum: random thought about profiling pipelines\n\nI wish there was a bit more pipeline-centric approach to profiling.  Maybe a toodling project for another day.\n\nBut thought I had, if profiling feels daunting, is to manually break your pipeline up until you track down the bottleneck:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ndo_1 <- function(dat) {\n  dat |>\n  filter(!is.na(air_time), !is.na(tailnum), !is.na(dep_delay)) \n}\n\ndo_2 <- function(temp)\n  temp |>\n  group_by(tailnum) |>\n  summarise(\n    mean_air_time = mean(air_time),\n    sd_air_time = sd(air_time),\n    n = n(),\n    delay_score = sum((dep_delay)^2) / n()\n  ) \n\n\ndo_3 <- function(temp) {\n  temp |>\n  left_join(planes, by = \"tailnum\") |>\n  mutate(\n    model_length = str_length(model),\n    manufacturer_upper = str_to_upper(manufacturer)\n  ) \n}\n\ndo_4 <- function(temp) {\n\n  temp |>\n    filter(!is.na(model_length), n > 50) |>\n    arrange(desc(delay_score))\n}\n\n```\n:::\n\n\n\nI'll just be simple and split it up with `tictoc()`, but you could probably take a more systematic appraoch.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\ntemp <- do_1(flights_big)\ntoc()\n#> 0.236 sec elapsed\n\ntic()\ntemp <- do_2(temp)\ntoc()\n#> 0.113 sec elapsed\n\ntic()\ntemp <- do_3(temp)\ntoc()\n#> 0.001 sec elapsed\n\ntic()\ntemp <- do_4(temp)\ntoc()\n#> 0.001 sec elapsed\n```\n:::\n\n\n\n\nI don't really think the above was worth the effort... but consider this my official wish for a pipeline-step-measuring profiler!  My vision would be that you put the pipeline through the profiler, and get back time/memory benchmarks for *only the functions exposed in the pipeline*.  None of this `vec_slice` business; just a measurement on each successive step of the pipe.\n\n## Conclusion\n\nThis actually took longer than expected, mostly trying to understand the small differences in syntax, input structure, and output info of the various functions.\n\n### Takeaway messages:\n\n* Most of us just need a quick timer, and we can do that easily with `proc.time()` or `system.time()` or `tictoc()`\n\n* If you want to (a) average many runs of the speed test and/or (b) compare different solutions, use `microbenchmark()`. If you want to see how speed scales with size, use `bench::mark()`\n\n* Profiling is really really helpful for pinpointing the problem.  `profviz` gets you answers quickly; `RProf()` and friends get you all the info.  But neither of these is as beginner/intermediate friendly as I would like.\n\n### Other little notes\n\n* If you want to get extra fancy with benchmarking, especially for purposes of checking if code updates on GitHub are actually improvements, check out the `atime` package - [great blog post about it here](https://rdatatable-community.github.io/The-Raft/posts/2024-10-10-Performance-Doris_Amoakohene/)\n\n* I'm aware there are other benchmarking packages, e.g. `rbenchmark`.  I'm less familiar with those but would love to learn more, if you think there's a reason a different one might be preferred!\n\n* [Here is a short post](https://rdatatable-community.github.io/The-Raft/posts/2025-07-14-memory_R-jangorecki/) that gets deep in the weeds on benchmarking memory, including allocations in C. \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/jquery-3.7.1/jquery.min.js\"></script>\n<script src=\"../../site_libs/d3-3.5.6/d3.min.js\"></script>\n<link href=\"../../site_libs/profvis-0.3.6.9000/profvis.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/profvis-0.3.6.9000/profvis.js\"></script>\n<script src=\"../../site_libs/profvis-0.3.6.9000/scroll.js\"></script>\n<link href=\"../../site_libs/highlight-11.10.0/textmate.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/highlight-11.10.0/highlight.min.js\"></script>\n<script src=\"../../site_libs/profvis-binding-0.4.0/profvis.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}